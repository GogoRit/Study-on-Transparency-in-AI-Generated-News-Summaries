{
    "title": "AI Bias Could Put Women\u2019s Lives At Risk - A Challenge For Regulators",
    "meta_title": "",
    "description": "Gender bias in artificial intelligence could put women's lives at risk. Can regulators tackle bias in AI?",
    "meta_description": "",
    "text_headers": "More From Forbes\nAI Bias Could Put Women\u2019s Lives At Risk - A Challenge For Regulators\n 300 Billion Crypto Price Crash Suddenly Accelerates As Bitcoin  Ethereum And XRP Traders Brace For A Fed Shock\nApple\u2019s Surprise Update Just Made iPhone More Like Samsung\nNew Gmail Security Rules You Have 14 Days To Comply  Google Says",
    "text": "AI Bias Could Put Women\u2019s Lives At Risk - A Challenge For RegulatorsSubscribe To NewslettersSign InBETAThis is a BETA experience. You may opt-out by\u00a0clicking hereMore From ForbesMar 18, 2024,01:47pm EDTHow Pet Tech Company Petcube Is Making Pet Parenting More Accessible To Every HumanMar 18, 2024,10:15am EDTHere\u2019s How Companies Can Integrate DEI Into Their Corporate StrategyMar 17, 2024,08:00am EDTYounger Generations Want To Change Jobs. Here\u2019s How Employers Can Keep ThemMar 15, 2024,09:53am EDTLong-Standing Federal And State Laws Protect And Help People With DisabilitiesMar 14, 2024,08:30pm EDTHow AI Is Reshaping Social Media Platforms And 5 Tips For SuccessMar 14, 2024,04:58pm EDTBegin With The End In Mind: Create An Impact Inclusion StatementMar 14, 2024,09:00am EDTWhite Men\u2019s Role In Advancing Equity And InclusionMar 13, 2024,09:00am EDTGen AI Is Rising Fast: How We Ensure Black Americans Rise With ItEdit StoryForbesLeadershipDiversity, Equity & InclusionAI Bias Could Put Women\u2019s Lives At Risk - A Challenge For RegulatorsCarmen NiethammerFormer ContributorOpinions expressed by Forbes Contributors are their own.I am a private sector development expert and gender diversity leader.Mar 2, 2020,04:19am ESTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to LinkedinWhen the European Commission released the long awaited white paper \u201cOn Artificial Intelligence - A European approach to excellence and trust\u201d on February 19, much of the initial public reaction focused on potential AI regulation further challenging the EU\u2019s position in light of fierce technological competition from China and the United States.\n\nFew discussed the European Commission\u2019s document mention of gender and ethical guidelines. Importantly, the white paper calls for \u201crequirements to take reasonable measures aimed at ensuring that [the] use of AI systems does not lead to outcomes entailing prohibited discrimination.\u201d Why does it matter?\n\n\nThis is not simply about a theoretical approach to discrimination. It is largely also about saving (women\u2019s) lives - and ensuring that essential products and services meet the needs of both women and men. However, if artificial intelligence is based on \u201cbad\u201d data sourced predominantly from men and/or based on male profiles, terrible things can happen.\n\nTake the concrete example of seatbelts, headrests and airbags in cars which have been designed mainly based on data collected from car crash dummy tests using the physique of men and their seating position. Women\u2019s breasts and pregnant bodies don't feed into the \u201cstandard\u201d measurements. As a result, women are 47% more likely to be seriously insured and 17% more likely to die than a man in a similar accident explain Caroline\u00a0Criado Perez,\u00a0author of Invisible Women, and Lauren Klein, co-author of \u00a0Data Feminism, in a recent BBC interview.\n\n\nWhile the gender gap in data is not always life threatening, the design and use of artificial intelligence models in different industries can significantly disadvantage women\u2019s lives. And while there is agreement that lots of good data can indeed help close gender gaps, there remain concerns that if the \u201cright\u201d questions are not being asked in the data collection process (including by women), gender gaps can actually widen when algorithms are misinformed. This does not only have negative impacts on women, but also business and economies.The humanoid robot Pepper is intended \"to make people enjoy life\", enhance people's lives, ... [+] facilitate relationships, have fun with people and connect people with the outside world. (Photo by Paco Freire/SOPA Images/LightRocket via Getty Images)LightRocket via Getty Images\nMORE FOR YOU 300 Billion Crypto Price Crash Suddenly Accelerates As Bitcoin  Ethereum And XRP Traders Brace For A Fed ShockApple\u2019s Surprise Update Just Made iPhone More Like SamsungNew Gmail Security Rules You Have 14 Days To Comply  Google Says\nThe gender data gap in health\nGender gaps in health are not only based on women\u2019s biological and socio-economic differences: medical studies which can exclude representative samples of women (including pregnant women, women in menopause, or women using birth control pills) may result in medical advice that is not necessarily suitable for the female body suggests Alexandra Kautzky-Willer, head of the Gender Medicine Unit at the Medical University of Vienna, Austria.\n\nFor example, over many decades cardio-vascular diseases were considered a men\u2019s illness. Today, online apps based on data mainly collected from men may suggest to a female user that her symptoms of pain in the left arm and back may be due to depression. The medical app might advise the woman to see the doctor in a couple of days. In contrast, a male user of the app is more likely to be asked to immediately contact his doctor based on a diagnosis of a possible heart attack. Yet, it is clear that women can also be victims of heart attacks.\n\n\n\u201cThere are huge data gaps regarding the lives and bodies of women,\u201d finds Prof. Dr. Sylvia Thun, director of eHealth at Charit\u00e9 of the Berlin Institute of Health. Many medical algorithms are, for example, based on U.S. military personnel data where women in some areas only represent 6%. Short of being able to drastically increase the numbers of women serving in the military (and thus enhance the female sample size), Thun suggests that scientists, practitioners and policy-makers need to work together to ensure that medical apps are gender-informed and take into consideration relevant data from women.\nIn addition to gender bias, AI faces other diversity bias challenges, including race. This can particularly be of concern when AI technology is supposed to diagnose skin cancer for which the accurate detection of skin color and its variances matter. Consider the example of face recognition algorithms which were studied by Algorithmic Justice League founder Joy Buolamwini. She found that the share of input images on which various facial recognition algorithms were based consisted of 80% images of white persons and 75% male faces. As a result, the algorithms had a high accuracy of 99% in detecting male faces. However, the system\u2019s ability to recognize black women was significantly lower at only 65% of the time. Thus, focusing on gender only is not likely to solve other intersectionality issues in AI.\nTo better serve\u00a0 business and society, fighting algorithmic bias needs to be a priority. \u201cBy 2022, 85% of AI projects will deliver erroneous outcomes due to bias in data, algorithms or the teams responsible for managing them. This is not just a problem for gender inequality \u2013 it also undermines the usefulness of AI\u201d according to Gartner, Inc.\nIncreasing the number of women in tech\nGiven that humans are responsible for building algorithms, social biases are likely to be significant. Many argue that one promising way of ensuring that historical gender bias does not get amplified and projected into the future is to increase the diversity of thought through the number of women in tech. Only 22% of AI professionals globally are female, compared to 78% who are male according to the\u00a0World Economic Forum.\nAt eight large tech companies, Bloomberg found that only 20% of the technical roles are filled by women. At Facebook and Google, less than 2% of technical roles are filled by black employees. Tech organizations not only recruit fewer women than men, they also lose them at a faster rate. Globally, women account for only 25% of workers in science, technology, engineering and mathematics (STEM), but only make-up 9% of leaders in those fields according to the Boston Consulting Group.\nLooking at AI talent globally, the one European country that follows the United States and India in third place is Germany. Yet, Germany is also among the countries with the largest AI gender gap. Here only 16% of the AI talent pool is female.\nIn Germany, a #SheHealth initiative was launched in 2016 to increase women\u2019s leadership in eHealth, a sector which in Germany has been significantly dominated by men in comparison to its neighbors Austria and the Netherlands. This is despite the fact that more than 50% of all medical students in Germany are female since the turn of the century. #SheHealth not only aims to increase women\u2019s leadership in Health and IT for career networking and role model purposes. Importantly #SheHealth calls on its members to contribute to strategies and technical innovation to ensure that digital solutions in health are responsive to women\u2019s needs.\nGovernments\u2019 role in managing (gender) bias in AI \nEU Scream, a nonprofit journalism organization based in Brussels, recently hosted an event regarding \u201cautomating bias in the age of AI perpetuating gender discrimination.\u201d Bringing together policy makers and technological experts, there was agreement that meaningful AI regulation is definitely needed to better manage and prevent AI bias. Panelists and members of the audience were, however, skeptical of governments not having the necessary understanding of new technological advances and their potential impact on humans.\nWhile the concept of discrimination is mostly understood (and historically supported by legislation and judicial decisions), one fiercely debated issue is the concept of \u201cfairness\u201d in AI. This is likely to become a battleground between the business world and policy makers.\nShort of regulations, one potential solution to ensure that AI is responsive to gender considerations and other ethical concerns is the application of certification processes. \u201cMost businesses, particularly tech startups, are concerned about making money and are under extreme time pressure to meet investors\u2019 demands. They don\u2019t have the time to worry about gender,\u201d explains Aikaterini Liakopoulou at EIT Digital. \u201cYet, businesses are always looking to brand themselves. Obtaining an AI certification can further distinguish companies and better position them in the investor and consumer markets.\u201d It turns out, only half of businesses across Europe have policies and procedures in place to identify and address ethical considerations\u2014either in the initial design of AI applications or in their behavior after the system is launched, according to Catalyst.\nIn fact, Denmark has just launched the prototype of a Data Ethics Seal which is backed by Danish companies who view the seal as an opportunity to gain a competitive edge. Malta introduced a voluntary certification system for AI - initially targeting its public sector institutions. \u201cIf the EU fails to provide an EU-wide approach, there is a real risk of fragmentation in the internal market, which would undermine the objectives of trust, legal certainty and market uptake\u201d states the European Commission\u2019s recently released white paper.\n\"One of the biggest drivers of European economic success has been the fact that we have rule of law. Many studies point to the relation between strong judicial systems and strong economic activity,\u201d highlights Samira Rafaela, Member of the European Parliament from the Netherlands who is also a member of the Committee on Women's Rights and Gender Equality. \u201cToday we see that not everyone in society enjoys the equal rights they have on paper. We should fix that, not exacerbate that by perpetuating biases in automated processes. This is the right thing to do and will benefit all.\"\nWhat\u2019s next\nWomen\u2019s organizations are increasingly engaged in the public discourse on gender and AI. Take the example of Germany: in a policy paper entitled \u201cAchieving a Gender-equitable Digital Transformation\u201d the National Council of German Women\u2019s Organizations demands\u2014among others - that \u201calgorithms and AI applications must be designed in such a way that any discrimination towards women in all their diversity is ruled out. This must be verifiable.\u201d\nThe organization also calls on the German federal government to require companies to guarantee the ethically responsible and anti-discriminatory design and use of algorithms.\nWhat is clear is that the European Commission has their work cut out for themselves: the Commission\u2019s Advisory Committee on Equal Opportunities for Women and Men is currently preparing an \u201cOpinion on Artificial Intelligence.\u201d It will present an analysis of the impacts of artificial intelligence on gender equality that is expected to be adopted by the committee in early 2020.\nAs for an update on potential EU regulatory frameworks, stay tuned also for a new report by the European Network of Equality Bodies (Equinet) on Regulating AI: the new role for Equality Bodies \u2013 Meeting the new challenges to equality and non-discrimination from increased digitalisation and the use of AI, which is expected in early 2020.\nFollow me on\u00a0LinkedIn.\u00a0Carmen NiethammerEditorial StandardsPrintReprints & Permissions"
}