# -*- coding: utf-8 -*-
"""DSCI-601_BiasDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wHbOjlK-GrjryiuK-Hb-dLlhdp_2ygEe

Installing dataset

Installing required dependencies
"""

#!pip install transformers
#!pip install datasets
#!pip install detoxify

"""Importing files"""

from datasets import load_dataset, concatenate_datasets
import pandas as pd
import tensorflow as tf
from transformers import TFRobertaForSequenceClassification,RobertaTokenizer,AutoTokenizer, TFAutoModelForSequenceClassification,pipeline,TextClassificationPipeline,AutoModelForSequenceClassification,BertTokenizer, TFBertForSequenceClassification
from prettytable import PrettyTable
from detoxify import Detoxify
import torch

"""Using dataset *cnn_dailymail* for running bias models"""

combined_dataset = concatenate_datasets([load_dataset('cnn_dailymail', '1.0.0')['train']])

print("Combined Length")
print(len(combined_dataset))

"""Put all highlights(summaries of new articles) in a dataframe"""

df_train_highlights = pd.DataFrame({'highlights': [article['highlights'] for article in combined_dataset]})

"""Using 1st value to test models"""

predict_val=df_train_highlights['highlights'].iloc[0]

# BIAS https://huggingface.co/d4data/bias-detection-model
#trained on MBAD Dataset to detect bias and fairness in sentences (news articles). This model was built on top of distilbert-base-uncased model

# Initialize the tokenizer and model for bias detection
tokenizer_bias = AutoTokenizer.from_pretrained("d4data/bias-detection-model")
model_bias = TFAutoModelForSequenceClassification.from_pretrained("d4data/bias-detection-model")

# Initialize the pipeline for text classification using the bias detection model
classifier_bias = pipeline('text-classification', model=model_bias, tokenizer=tokenizer_bias) # cuda = 0,1 based on gpu availability

# Input: A text string
# Expected output: Dictionary containing the classification label and the score
# Data types:
# - Input: str
# - Output: dict

# TOXIC https://huggingface.co/unitary/toxic-bert
#Trained models & code to predict toxic comments on 3 Jigsaw challenges:
#Toxic comment classification, Unintended Bias in Toxic comments, Multilingual toxic comment classification.

# Initialize the tokenizer and model for the toxic comment classification
tokenizer_toxic1= AutoTokenizer.from_pretrained("unitary/toxic-bert")
model_toxic1 = AutoModelForSequenceClassification.from_pretrained("unitary/toxic-bert")

# Initialize the pipeline for text classification using the toxic comment classification model
classifier__toxic1 = pipeline('text-classification', model=model_toxic1, tokenizer=tokenizer_toxic1) # cuda = 0,1 based on gpu availability

# Input: A text string
# Expected output: Dictionary containing the classification label and the score
# Data types:
# - Input: str
# - Output: dict

# TOXIC https://huggingface.co/martin-ha/toxic-comment-model
#This model is a fine-tuned version of the DistilBERT model (Transformer model trained by distilling BERT bas) to classify toxic comments.

# Initialize the tokenizer and model for the toxic comment classification
tokenizer_toxic = AutoTokenizer.from_pretrained("martin-ha/toxic-comment-model")
model_toxic = AutoModelForSequenceClassification.from_pretrained("martin-ha/toxic-comment-model")

# Initialize the pipeline for text classification using the toxic comment classification model
classifier__toxic =  TextClassificationPipeline(model=model_toxic, tokenizer=tokenizer_toxic)

# Input: A text string
# Expected output: Dictionary containing the classification label and the score
# Data types:
# - Input: str
# - Output: dict

# Load pre-trained BERT model and tokenizer (https://huggingface.co/google-bert/bert-base-uncased)
#BERT is a transformers model pretrained on a large corpus of English data in a self-supervised fashion

# Initialize the tokenizer for the base uncased BERT model
tokenizer_bert_base_uncased = BertTokenizer.from_pretrained("bert-base-uncased")

# Initialize the model for sequence classification using the base uncased BERT model
model_bert_base_uncased = TFBertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)

# Input: A text string
# Expected output: Tensor containing the logits for each class
# Data types:
# - Input: str
# - Output: Tensor

# Load pre-trained RoBERTa model and tokenizer

#Initialize the tokenizer for the base RoBERTa model
tokenizer_roberta_base = RobertaTokenizer.from_pretrained("roberta-base")

# Initialize the model for sequence classification using the base RoBERTa model
model_roberta_base = TFRobertaForSequenceClassification.from_pretrained("roberta-base", num_labels=9)

# Input: A text string
# Expected output: Tensor containing the logits for each class
# Data types:
# - Input: str
# - Output: Tensor

# Load pre-trained RoBERTa model and tokenizer
# Initialize the text classification pipeline using the "SamLowe/roberta-base-go_emotions" model
classifier = pipeline(task="text-classification", model="SamLowe/roberta-base-go_emotions", top_k=None)

# Input: List of sentences to predict the emotions for
# Expected output: List of dictionaries, each containing the predicted emotion label and its score
# Data types:
# - Input: list of str
# - Output: list of dict

# Example usage:
sentences = [str(predict_val)]
predictions = classifier(sentences)

# Assuming `predictions` is a list of dictionaries containing 'score' keys
max_score_values = [max(prediction, key=lambda x: x['label']) for prediction in predictions]

# Print
print(max_score_values)

# Tokenize the input text for both models
inputs_bert = tokenizer_bert_base_uncased(predict_val, padding=True, truncation=True, max_length=128, return_tensors="tf")
inputs_roberta = tokenizer_roberta_base(predict_val, padding=True, truncation=True, max_length=128, return_tensors="tf")

# Perform inference for both models
outputs_bert = model_bert_base_uncased(inputs_bert)
outputs_roberta = model_roberta_base(inputs_roberta)

# Get predicted labels for both models
predictions_bert = tf.nn.softmax(outputs_bert.logits, axis=-1)
predictions_roberta = tf.nn.softmax(outputs_roberta.logits, axis=-1)

# Get predicted label for BERT-based model
label_bert = "toxic" if tf.argmax(predictions_bert, axis=1).numpy()[0] == 1 else "not toxic"

# Get predicted label for RoBERTa-based model
label_roberta = "toxic" if tf.argmax(predictions_roberta, axis=1).numpy()[0] == 1 else "not toxic"

# Assuming inputs_bert and inputs_roberta are your input tensors for the BERT-based and RoBERTa-based models, respectively

emotion_labels = ['neutral', 'happiness', 'sadness', 'anger', 'fear', 'surprise']
# Perform inference and get predicted emotion category for BERT-based model
outputs_bert = model_bert_base_uncased(inputs_bert)
predicted_label_id_bert = tf.argmax(outputs_bert.logits, axis=1).numpy()[0]
if predicted_label_id_bert >= len(emotion_labels):
    print("The model predicted a class that is not present in the emotion_labels list.")
    predicted_label_roberta="NA"
else:
    predicted_label_bert = emotion_labels[predicted_label_id_bert]

# Perform inference and get predicted emotion category for RoBERTa-based model
outputs_roberta = model_roberta_base(inputs_roberta)
predicted_label_id_roberta = tf.argmax(outputs_roberta.logits, axis=1).numpy()[0]
if predicted_label_id_roberta >= len(emotion_labels):
    print("The model predicted a class that is not present in the emotion_labels list.")
    predicted_label_roberta="NA"
else:
  predicted_label_roberta = emotion_labels[predicted_label_id_roberta]

# Tokenize the input text
# Input: predict_val (list of str) - List of input texts to be tokenized
inputs_bert = tokenizer_bert_base_uncased(predict_val, padding=True, truncation=True, max_length=128, return_tensors="tf")
inputs_roberta = tokenizer_roberta_base(predict_val, padding=True, truncation=True, max_length=128, return_tensors="tf")

# Perform inference and get predicted label for BERT-based model
# Expected output: label_bert (str) - Predicted label for the BERT-based model ("sexist" or "not sexist")
outputs_bert = model_bert_base_uncased(inputs_bert)
predictions_bert = tf.nn.softmax(outputs_bert.logits, axis=-1)
label_bert = "sexist" if tf.argmax(predictions_bert, axis=1).numpy()[0] == 1 else "not sexist"

# Perform inference and get predicted label for RoBERTa-based model
# Expected output: label_roberta (str) - Predicted label for the RoBERTa-based model ("sexist" or "not sexist")
outputs_roberta = model_roberta_base(inputs_roberta)
predictions_roberta = tf.nn.softmax(outputs_roberta.logits, axis=-1)
label_roberta = "sexist" if tf.argmax(predictions_roberta, axis=1).numpy()[0] == 1 else "not sexist"

"""Outputs of each model"""

print(f"Summary String: {predict_val}")

from prettytable import PrettyTable

# Create a PrettyTable instance
table = PrettyTable()

# Add columns to the table
table.field_names = ["Category", "Response"]

# Add data to the table
table.add_row(["Bias Detection Model", classifier_bias(str(predict_val))])
table.add_row(["Max Value Response from Roberta", max_score_values])
table.add_row(["Toxic BERT", classifier__toxic1(str(predict_val))])
table.add_row(["Toxic Comment Model", classifier__toxic(str(predict_val))])
table.add_row(["Response from BERT-based model", label_bert])
table.add_row(["Response from RoBERTa-based model", label_roberta])
table.add_row(["Predicted Emotion Category from BERT", predicted_label_bert])
table.add_row(["Predicted Emotion Category from RoBERTa", predicted_label_roberta])
table.add_row(["Response from BERT-based model", label_bert])
table.add_row(["Response from RoBERTa-based model", label_roberta])

# Print the table
print(table)

# https://huggingface.co/SamLowe/roberta-base-go_emotions
# Model trained from roberta-base (https://huggingface.co/FacebookAI/roberta-base) on the go_emotions dataset(https://huggingface.co/datasets/go_emotions) for multi-label classification.

# Initialize Detoxify models
# Input: 'original', 'unbiased', 'multilingual' (str) - Type of Detoxify model to initialize
original_model = Detoxify('original')
unbiased_model = Detoxify('unbiased')
multilingual_model = Detoxify('multilingual')

# Get predictions from all three models
# Input: predict_val (list of str) - List of input texts to predict the toxicity of
original_results = original_model.predict(predict_val)
unbiased_results = unbiased_model.predict(predict_val)
multilingual_results = multilingual_model.predict(predict_val)

# Create a PrettyTable instance
table = PrettyTable()

# Add columns to the table
table.field_names = ["Model", "Category", "Probability"]

# Add data to the table
for model_name, results in [("Original", original_results.items()), ("Unbiased", unbiased_results.items()), ("Multilingual", multilingual_results.items())]:
    for category, probability in results:
        table.add_row([model_name, category, probability])

# Print the table
print(table)

#https://huggingface.co/bucketresearch/politicalBiasBERT
# Paper: We Can Detect Your Bias: Predicting the Political Ideology of News Articles

# Assuming predict_val is a single text string
text = str(predict_val)

# Initialize the tokenizer and model
tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_pretrained("bucketresearch/politicalBiasBERT")

# Tokenize the input text and prepare it for the model
inputs = tokenizer(text, return_tensors="pt")
labels = torch.tensor([0])  # Assuming the label is always 0 for this task

# Perform inference
outputs = model(**inputs, labels=labels)
loss, logits = outputs[:2]

# Mapping of the output logits to political bias categories
# [0] -> Left: Typically associated with liberal or progressive views.
#          This may include support for social welfare programs, environmental protection,
#          and progressive taxation.
# [1] -> Center: Represents a more moderate or centrist position.
#               This could indicate a balance between liberal and conservative views,
#               often emphasizing compromise and pragmatism.
# [2] -> Right: Associated with conservative or traditional views.
#          This may include support for free market economics, limited government intervention,
#          and traditional social values.

print(predict_val)
print(logits.softmax(dim=-1)[0].tolist())